{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libreria de Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('cess_esp')\n",
    "#   nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]    |     ..\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso Final POS - Ejemplo español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"El oso caza abejas negras. Ademas, vive en la montaña\"\n",
    "\n",
    "#\"He estado lidiando con la instalación de los programas. No sé qué puede estar mal. El día está pesado!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline del Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libreria NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse import DependencyGraph\n",
    "from nltk import pos_tag\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yerzy_hqbafrm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love this pretty dog. He is always by mu sides. Besides, he likes to eat a lot.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Segmentation:\n",
      "['I love this pretty dog.', 'He is always by mu sides.', 'Besides, he likes to eat a lot.']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Segmentation:\")\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Word Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Tokenization:\n",
      "['I', 'love', 'this', 'pretty', 'dog', '.', 'He', 'is', 'always', 'by', 'mu', 'sides', '.', 'Besides', ',', 'he', 'likes', 'to', 'eat', 'a', 'lot', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stemming - Encontrar la raíz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming:\n",
      "['i', 'love', 'thi', 'pretti', 'dog', '.', 'he', 'is', 'alway', 'by', 'mu', 'side', '.', 'besid', ',', 'he', 'like', 'to', 'eat', 'a', 'lot', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(\"\\nStemming:\")\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lematizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization:\n",
      "['I', 'love', 'this', 'pretty', 'dog', '.', 'He', 'is', 'always', 'by', 'mu', 'side', '.', 'Besides', ',', 'he', 'like', 'to', 'eat', 'a', 'lot', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"\\nLemmatization:\")\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stop Word Analysis: identificar y eliminar palabras prescindibles de un texto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop Word Analysis:\n",
      "['love', 'pretty', 'dog', '.', 'always', 'mu', 'sides', '.', 'Besides', ',', 'likes', 'eat', 'lot', '.']\n"
     ]
    }
   ],
   "source": [
    "#Las palabras vacías son palabras de uso común que generalmente se consideran de poco valor.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "print(\"\\nStop Word Analysis:\")\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. y 7. Parsing de dependencia y speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part of Speech Tagging:\n",
      "[('love', 'VB'), ('pretty', 'RB'), ('dog', 'NN'), ('.', '.'), ('always', 'RB'), ('mu', 'JJ'), ('sides', 'NNS'), ('.', '.'), ('Besides', 'NNP'), (',', ','), ('likes', 'VBZ'), ('eat', 'NN'), ('lot', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = pos_tag(filtered_words)\n",
    "print(\"\\nPart of Speech Tagging:\")\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('this', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(words)\n",
    "tagged[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree('S', [('I', 'PRP'), ('love', 'VBP'), ('this', 'DT'), ('pretty', 'JJ'), ('dog', 'NN'), ('.', '.'), ('He', 'PRP'), ('is', 'VBZ'), ('always', 'RB'), ('by', 'IN'), ('mu', 'NN'), ('sides', 'NNS'), ('.', '.'), ('Besides', 'NNS'), (',', ','), ('he', 'PRP'), ('likes', 'VBZ'), ('to', 'TO'), ('eat', 'VB'), ('a', 'DT'), ('lot', 'NN'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print(entities.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de árboles jerárquicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Verifica si el modelo se puede cargar\n",
    "try:\n",
    "    nlp = spacy.load('es_core_news_md')\n",
    "    print(\"Modelo cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"El oso caza abejas negras. Ademas, vive en la montaña\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El -> DET\n",
      "oso -> NOUN\n",
      "caza -> VERB\n",
      "abejas -> NOUN\n",
      "negras -> ADJ\n",
      ". -> PUNCT\n",
      "Ademas -> PROPN\n",
      ", -> PUNCT\n",
      "vive -> VERB\n",
      "en -> ADP\n",
      "la -> DET\n",
      "montaña -> NOUN\n"
     ]
    }
   ],
   "source": [
    "# create spacy \n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text,'->',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"e1b0ffc98519488cab07653e69735e6a-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">El</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">oso</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">caza</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">abejas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">negras.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Ademas,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">vive</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">montaña</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-5\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-6\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1b0ffc98519488cab07653e69735e6a-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1b0ffc98519488cab07653e69735e6a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy \n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulacion de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = ['Necesito un bowl de acai porfavor.',\n",
    " 'Me da un jugo de tumbo?',\n",
    " 'Vendame dos hamburguesas de barbacoa.',\n",
    " 'voy a llevar una hamburguesa mediana con papas.',\n",
    " 'A mí me gustaría la ensalada César.',\n",
    " 'para empezar, voy a pedir la sopa de tomate.',\n",
    " 'Para el postre quiero una torta de durazno',\n",
    " 'Para beber, una sangría, por favor.',\n",
    " 'De primero tomaremos la crema de verduras y una ensalada mixta.',\n",
    " 'Probaremos el arroz con leche y la tarta de chocolate.',\n",
    " 'Tomaré una cerveza, por favor.',\n",
    " '¿Me da un postre de canela?','Deme un pollo frito con curry.',\n",
    " 'Me trae una pizza de palmito',\n",
    " 'Deme tres trancapechos',\n",
    " 'Deme una chuleta de carne con huevo',\n",
    " 'Deme tres tacos con jalapenios',\n",
    " 'Traigame cinco pizzas con jamon y tomate',\n",
    " 'Quiero 6 pollos personales',\n",
    " 'Quisiera tres hamburguesas con pepino',\n",
    " 'Me trae papas fritas',\n",
    " 'vendame cinco empanadas de pollo',\n",
    " 'Llevaré tres sandwich de palta',\n",
    " 'Necesito una pasta de albahaca',\n",
    "      'Quiero llevar 2 pizzas con piña']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para ADP mark\n",
      "beber VERB ROOT\n",
      ", PUNCT punct\n",
      "una DET det\n",
      "sangría NOUN obj\n",
      ", PUNCT punct\n",
      "por ADP advmod\n",
      "favor NOUN fixed\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(txt1[7])\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuente spacy: https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/Multilingual/Spanish/03-POS-Keywords-Spanish.html\n",
    "    \n",
    "    Instalar la linea inferior solo una vez"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
